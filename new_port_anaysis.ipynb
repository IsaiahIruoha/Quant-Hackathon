{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values per column:\n",
      "date                0\n",
      "permno              0\n",
      "stock_exret         0\n",
      "market_equity       0\n",
      "ret_12_1          353\n",
      "be_me            4808\n",
      "ivol_capm_21d       1\n",
      "en                  0\n",
      "dtype: int64\n",
      "\n",
      "Number of rows before dropping rows with null values: 158980\n",
      "Number of rows after dropping rows with null values: 153848\n"
     ]
    }
   ],
   "source": [
    "# ---- STEP 1: Load and Merge Data ----\n",
    "# Load relevant columns from hackathon_sample_v2.csv and output.csv\n",
    "hackathon_sample_v2_path = \"/Users/isaiah/Desktop/Career/Clubs : Groups/Quant Hackathon/McGill-FIAM Asset Management Hackathon/Quant-Hackathon/hackathon_sample_v2.csv\"\n",
    "output_path = \"/Users/isaiah/Desktop/Career/Clubs : Groups/Quant Hackathon/McGill-FIAM Asset Management Hackathon/Quant-Hackathon/output.csv\"\n",
    "\n",
    "hackathon_sample_v2 = pd.read_csv(hackathon_sample_v2_path, usecols=['permno', 'date', 'market_equity', 'be_me', 'ret_12_1', 'ivol_capm_21d', 'stock_exret'])\n",
    "output = pd.read_csv(output_path, usecols=['permno', 'date', 'en'])\n",
    "\n",
    "# Convert 'date' in hackathon_sample_v2 from YYYYMMDD integer format to datetime\n",
    "hackathon_sample_v2['date'] = pd.to_datetime(hackathon_sample_v2['date'], format='%Y%m%d')\n",
    "\n",
    "# Convert 'date' in output to datetime if needed\n",
    "output['date'] = pd.to_datetime(output['date'])\n",
    "# Now merge the data on 'permno' and 'date'\n",
    "pred = pd.merge(hackathon_sample_v2, output, on=['permno', 'date'], how='inner')\n",
    "\n",
    "null_counts = pred.isnull().sum()\n",
    "print(\"Number of null values per column:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Drop rows that have any null values\n",
    "pred_cleaned = pred.dropna(axis=0)\n",
    "\n",
    "# Display the number of rows before and after dropping rows with null values\n",
    "print(\"\\nNumber of rows before dropping rows with null values:\", len(pred))\n",
    "print(\"Number of rows after dropping rows with null values:\", len(pred_cleaned))\n",
    "\n",
    "pred = pred_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 2: Multi-Signal Ensemble with Random Forest ----\n",
    "# Include multiple signals (value, momentum, risk) alongside ElasticNet predictions\n",
    "pred['value_signal'] = pred['be_me']  # Book-to-market ratio (value factor)\n",
    "pred['momentum_signal'] = pred['ret_12_1']  # 12-month return (momentum factor)\n",
    "pred['risk_signal'] = 1 / pred['ivol_capm_21d']  # Inverse volatility (risk factor)\n",
    "pred['en_signal'] = pred['en']  # ElasticNet-predicted return\n",
    "\n",
    "# Define the features (signals) and target (actual returns)\n",
    "features = pred[['value_signal', 'momentum_signal', 'risk_signal', 'en_signal']]\n",
    "target = pred['stock_exret']\n",
    "\n",
    "# Train the Random Forest model to generate predicted returns from signals\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predicted returns based on the multi-signal ensemble (including EN predictions)\n",
    "pred['predicted_return'] = rf_model.predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaiah/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/pandas/core/frame.py:10869: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  base_cov = np.cov(mat.T, ddof=ddof)\n",
      "/Users/isaiah/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/isaiah/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Quadratic form matrices must be symmetric/Hermitian.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m weights \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mVariable(n_assets)\n\u001b[1;32m     28\u001b[0m portfolio_return \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmatmul(bl_adjusted_returns, weights)\n\u001b[0;32m---> 29\u001b[0m portfolio_risk \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquad_form\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m objective \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mMaximize(portfolio_return \u001b[38;5;241m-\u001b[39m portfolio_risk)\n\u001b[1;32m     31\u001b[0m constraints \u001b[38;5;241m=\u001b[39m [cp\u001b[38;5;241m.\u001b[39msum(weights) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/cvxpy/atoms/quad_form.py:252\u001b[0m, in \u001b[0;36mquad_form\u001b[0;34m(x, P, assume_PSD)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assume_PSD:\n\u001b[1;32m    251\u001b[0m         P \u001b[38;5;241m=\u001b[39m psd_wrap(P)\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuadForm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one argument to quad_form must be non-variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/cvxpy/atoms/quad_form.py:42\u001b[0m, in \u001b[0;36mQuadForm.__init__\u001b[0;34m(self, x, P)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, P) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Atom representing :math:`x^T P x`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQuadForm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/cvxpy/atoms/atom.py:50\u001b[0m, in \u001b[0;36mAtom.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Convert raw values to Constants.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [Atom\u001b[38;5;241m.\u001b[39mcast_to_const(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_from_args()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/cvxpy/atoms/quad_form.py:58\u001b[0m, in \u001b[0;36mQuadForm.validate_arguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dimensions for arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mis_hermitian():\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuadratic form matrices must be symmetric/Hermitian.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Quadratic form matrices must be symmetric/Hermitian."
     ]
    }
   ],
   "source": [
    "# ---- STEP 3: Black-Litterman Optimization (Monthly Rebalancing) ----\n",
    "# Group the data by 'year' and 'month'\n",
    "monthly_results = []\n",
    "\n",
    "for (year, month), monthly_data in pred_cleaned.groupby([pred_cleaned['date'].dt.year, pred_cleaned['date'].dt.month]):\n",
    "    \n",
    "    # Define market weights and equilibrium return\n",
    "    monthly_data['market_weight'] = monthly_data['market_equity'] / monthly_data['market_equity'].sum()\n",
    "    market_equilibrium_return = np.dot(monthly_data['market_weight'], monthly_data['stock_exret'])\n",
    "    views = monthly_data['predicted_return']\n",
    "\n",
    "    tau = 0.05\n",
    "    bl_adjusted_returns = (1 - tau) * market_equilibrium_return + tau * views\n",
    "    bl_adjusted_returns = np.array(bl_adjusted_returns)\n",
    "\n",
    "    # Create covariance matrix based on asset returns\n",
    "    pivoted_returns = monthly_data.pivot(index='date', columns='permno', values='stock_exret')\n",
    "    cov_matrix = pivoted_returns.cov().values\n",
    "\n",
    "    # Ensure the covariance matrix is symmetric\n",
    "    cov_matrix = (cov_matrix + cov_matrix.T) / 2\n",
    "\n",
    "    # Number of assets\n",
    "    n_assets = len(bl_adjusted_returns)\n",
    "    \n",
    "    # Optimization for portfolio weights\n",
    "    weights = cp.Variable(n_assets)\n",
    "    portfolio_return = cp.matmul(bl_adjusted_returns, weights)\n",
    "    portfolio_risk = cp.quad_form(weights, cov_matrix)\n",
    "    objective = cp.Maximize(portfolio_return - portfolio_risk)\n",
    "    constraints = [cp.sum(weights) == 1]\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "    # Get the optimized portfolio weights\n",
    "    optimal_weights = weights.value\n",
    "    monthly_data['optimal_weight'] = optimal_weights\n",
    "\n",
    "    # Calculate portfolio return\n",
    "    monthly_data['portfolio_return'] = monthly_data['stock_exret'] * monthly_data['optimal_weight']\n",
    "    \n",
    "    # Store the monthly results\n",
    "    monthly_results.append(monthly_data)\n",
    "\n",
    "# Combine all monthly data back into one dataframe\n",
    "final_portfolio = pd.concat(monthly_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 4: Calculate Performance Metrics Based on Rebalanced Portfolio ----\n",
    "\n",
    "# 1. Sharpe Ratio (Annualized)\n",
    "sharpe_ratio = final_portfolio['portfolio_return'].mean() / final_portfolio['portfolio_return'].std() * np.sqrt(12)\n",
    "print(\"Sharpe Ratio:\", sharpe_ratio)\n",
    "\n",
    "# 2. Annualized Return\n",
    "annualized_return = final_portfolio['portfolio_return'].mean() * 12\n",
    "print(\"Annualized Return:\", annualized_return)\n",
    "\n",
    "# 3. Annualized Standard Deviation\n",
    "annualized_std_dev = final_portfolio['portfolio_return'].std() * np.sqrt(12)\n",
    "print(\"Annualized Standard Deviation:\", annualized_std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 5: CAPM Alpha and Information Ratio ----\n",
    "mkt_path = \"/Users/isaiah/Desktop/Career/Clubs : Groups/Quant Hackathon/McGill-FIAM Asset Management Hackathon/mkt_ind.csv\"\n",
    "mkt = pd.read_csv(mkt_path)\n",
    "\n",
    "# Create 'mkt_rf' by subtracting the risk-free rate from market return\n",
    "mkt['mkt_rf'] = mkt['sp_ret'] - mkt['rf']\n",
    "final_portfolio = final_portfolio.merge(mkt, how=\"inner\", on=[\"year\", \"month\"])\n",
    "\n",
    "# Perform CAPM regression (Newey-West standard errors)\n",
    "nw_ols = sm.ols(formula=\"portfolio_return ~ mkt_rf\", data=final_portfolio).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 3}, use_t=True)\n",
    "print(nw_ols.summary())\n",
    "\n",
    "# CAPM Alpha, Information Ratio\n",
    "alpha = nw_ols.params[\"Intercept\"]\n",
    "t_stat = nw_ols.tvalues[\"Intercept\"]\n",
    "info_ratio = alpha / np.sqrt(nw_ols.mse_resid) * np.sqrt(12)\n",
    "\n",
    "print(\"CAPM Alpha:\", alpha)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"Information Ratio:\", info_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 6: Maximum Drawdown ----\n",
    "final_portfolio[\"log_portfolio_return\"] = np.log(final_portfolio[\"portfolio_return\"] + 1)\n",
    "final_portfolio[\"cumsum_log_portfolio_return\"] = final_portfolio[\"log_portfolio_return\"].cumsum(axis=0)\n",
    "rolling_peak = final_portfolio[\"cumsum_log_portfolio_return\"].cummax()\n",
    "drawdown = rolling_peak - final_portfolio[\"cumsum_log_portfolio_return\"]\n",
    "max_drawdown = drawdown.max()\n",
    "print(\"Maximum Drawdown:\", max_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 7: Maximum Drawdown ----\n",
    "final_portfolio[\"log_portfolio_return\"] = np.log(final_portfolio[\"portfolio_return\"] + 1)\n",
    "final_portfolio[\"cumsum_log_portfolio_return\"] = final_portfolio[\"log_portfolio_return\"].cumsum(axis=0)\n",
    "rolling_peak = final_portfolio[\"cumsum_log_portfolio_return\"].cummax()\n",
    "drawdown = rolling_peak - final_portfolio[\"cumsum_log_portfolio_return\"]\n",
    "max_drawdown = drawdown.max()\n",
    "print(\"Maximum Drawdown:\", max_drawdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 7: Turnover Calculation ----\n",
    "def turnover_count(df):\n",
    "    stock_counts = df.groupby([\"year\", \"month\"])[\"permno\"].count().reset_index(name=\"count\")\n",
    "    stock_counts[\"count_next\"] = stock_counts[\"count\"].shift(-1)\n",
    "    stock_counts[\"turnover\"] = abs(stock_counts[\"count\"] - stock_counts[\"count_next\"]) / stock_counts[\"count\"]\n",
    "    return stock_counts[\"turnover\"].mean()\n",
    "\n",
    "long_portfolio = final_portfolio.nlargest(50, 'optimal_weight')\n",
    "short_portfolio = final_portfolio.nsmallest(50, 'optimal_weight')\n",
    "\n",
    "long_turnover = turnover_count(long_portfolio)\n",
    "short_turnover = turnover_count(short_portfolio)\n",
    "print(\"Long Portfolio Turnover:\", long_turnover)\n",
    "print(\"Short Portfolio Turnover:\", short_turnover)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEC292",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
